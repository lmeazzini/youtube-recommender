{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "import scikitplot as skplt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data.csv')\n",
    "df = df[df['y'].notnull()]\n",
    "\n",
    "df_clean = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Clean date attribute\n",
    "clean_date = df['watch-time-text'].str.extract(r\"(\\d+) de ([a-z]+)\\. de (\\d+)\")\n",
    "clean_date[0] = clean_date[0].dropna().astype(str)\n",
    "clean_date[2] = clean_date[2].dropna().astype(str)\n",
    "\n",
    "month_map = {\"jan\": \"Jan\",\n",
    "             \"fev\": \"Feb\",\n",
    "             \"mar\": \"Mar\",\n",
    "             \"abr\": \"Apr\",\n",
    "             \"mai\": \"May\",\n",
    "             \"jun\": \"Jun\",\n",
    "             \"jul\": \"Jul\",\n",
    "             \"ago\": \"Aug\",\n",
    "             \"set\": \"Sep\",\n",
    "             \"out\": \"Oct\",\n",
    "             \"nov\": \"Nov\",\n",
    "             \"dez\": \"Dec\"}\n",
    "\n",
    "clean_date[1] = clean_date[1].map(month_map)\n",
    "clean_date = clean_date.dropna().apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "df_clean['date'] = pd.to_datetime(clean_date, format=\"%d %b %Y\")\n",
    "\n",
    "# Clean view number\n",
    "views = df['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False)\n",
    "df_clean['views'] = views.str.replace(\".\", \"\").fillna(0).astype(int)\n",
    "\n",
    "# Makaing features DataFrame\n",
    "features = pd.DataFrame(index=df_clean.index)\n",
    "y = df['y'].copy()\n",
    "\n",
    "# Extracting time since publication feature\n",
    "features['time_since_pub'] = (pd.to_datetime(\"2020-03-15\") -  # HARDCODED\n",
    "                              df_clean['date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "# Extracting n of view feature\n",
    "features['views'] = df_clean['views']\n",
    "\n",
    "# Extracting n of view/day feature\n",
    "features['views_per_day'] = features['views'] / features['time_since_pub']\n",
    "\n",
    "# Droping time_since_pub to prevent bias\n",
    "features = features.drop(['time_since_pub'], axis=1)\n",
    "features['date'] = df_clean['date']\n",
    "features['index'] = features.index\n",
    "features = features.set_index('date').sort_index().dropna()\n",
    "\n",
    "y = pd.DataFrame(y)\n",
    "y['date'] = df_clean['date']\n",
    "y['index'] = y.index\n",
    "y = y.set_index('date').sort_index()\n",
    "y = y[y.index.notna()]\n",
    "\n",
    "# Splitting the data set - 60% train 40% validation\n",
    "n = len(features)\n",
    "n_train = np.ceil(n * 0.6) - 1\n",
    "n_val = n - n_train\n",
    "\n",
    "X_train, X_val = (features.reset_index().loc[:n_train],\n",
    "                  features.reset_index().loc[n_train+1:])\n",
    "y_train, y_val = y.reset_index().loc[:n_train], y.reset_index().loc[n_train+1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.set_index('index').drop('date', axis=1)\n",
    "y_train = y_train.set_index('index').drop('date', axis=1)\n",
    "X_val = X_val.set_index('index').drop('date', axis=1)\n",
    "y_val = y_val.set_index('index').drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['title'] = df['watch-title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_titles = df_clean.loc[X_train.index.tolist()]['title']\n",
    "val_titles = df_clean.loc[X_val.index.tolist()]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vec = TfidfVectorizer(min_df=2)\n",
    "title_bow_train = title_vec.fit_transform(train_titles)\n",
    "title_bow_val = title_vec.transform(val_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title = hstack([X_train, title_bow_train])\n",
    "X_val_title = hstack([X_val, title_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=6, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=1000, random_state=0, class_weight=\"balanced\", n_jobs=6)\n",
    "mdl.fit(X_train_title, y_train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss:  11.33728379028392\n",
      "avg_precision_score:  0.7095503582198881\n",
      "roc_auc:  0.7035914179104477\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the validation set\n",
    "val_proba = mdl.predict_proba(X_val_title)\n",
    "preds = mdl.predict(X_val_title)\n",
    "\n",
    "# Getting the metrics\n",
    "print('log_loss: ', log_loss(y_val, preds))\n",
    "print('avg_precision_score: ', average_precision_score(y_val, val_proba[:, 1]))\n",
    "print('roc_auc: ', roc_auc_score(y_val, val_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTIVE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:youtube_recommender]",
   "language": "python",
   "name": "conda-env-youtube_recommender-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
