{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import bs4 as bs4\n",
    "import json\n",
    "import glob\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../data/raw_data.csv\")\n",
    "df1 = df1[df1['y'].notnull()]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../data/active_label_done.csv\", index_col=0)\n",
    "df2 = df2[df2['y'].notnull()]\n",
    "df2['new_data'] = 1\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "average_precision_score(df2['y'],df2['p']), roc_auc_score(df2['y'],df2['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2.drop(\"p\", axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame(index=df.index)\n",
    "df_clean['new_data'] = df2['new_data']\n",
    "df_clean['new_data'].fillna(0, inplace=True)\n",
    "df_clean['title'] = df['watch-title']\n",
    "\n",
    "# Clean date attribute\n",
    "clean_date = df['watch-time-text'].str.extract(r\"(\\d+) de ([a-z]+)\\. de (\\d+)\")\n",
    "clean_date[0] = clean_date[0].dropna().astype(str)\n",
    "clean_date[2] = clean_date[2].dropna().astype(str)\n",
    "\n",
    "month_map = {\"jan\": \"Jan\",\n",
    "             \"fev\": \"Feb\",\n",
    "             \"mar\": \"Mar\",\n",
    "             \"abr\": \"Apr\",\n",
    "             \"mai\": \"May\",\n",
    "             \"jun\": \"Jun\",\n",
    "             \"jul\": \"Jul\",\n",
    "             \"ago\": \"Aug\",\n",
    "             \"set\": \"Sep\",\n",
    "             \"out\": \"Oct\",\n",
    "             \"nov\": \"Nov\",\n",
    "             \"dez\": \"Dec\"}\n",
    "\n",
    "clean_date[1] = clean_date[1].map(month_map)\n",
    "clean_date = clean_date.dropna().apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "df_clean['date'] = pd.to_datetime(clean_date, format=\"%d %b %Y\")\n",
    "\n",
    "# Clean view number\n",
    "views = df['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False)\n",
    "df_clean['views'] = views.str.replace(\".\", \"\").fillna(0).astype(int)\n",
    "\n",
    "# Makaing features DataFrame\n",
    "features = pd.DataFrame(index=df_clean.index)\n",
    "y = df['y'].copy()\n",
    "\n",
    "# Extracting time since publication feature\n",
    "features['time_since_pub'] = (pd.to_datetime(\"2020-03-24\") -  # HARDCODED\n",
    "                              df_clean['date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "# Extracting n of view feature\n",
    "features['views'] = df_clean['views']\n",
    "\n",
    "# Extracting n of view/day feature\n",
    "features['views_per_day'] = features['views'] / features['time_since_pub']\n",
    "\n",
    "# Droping time_since_pub to prevent bias\n",
    "features = features.drop(['time_since_pub'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Around 75% train and 25% to validation\n",
    "split_date = '2020-02-27'\n",
    "mask_train = (df_clean['date'] < split_date) & (df_clean['date'].notnull())\n",
    "mask_val = (df_clean['date'] >= split_date) & (df_clean['date'].notnull())\n",
    "\n",
    "X_train, X_val = features[mask_train.values], features[mask_val.values]\n",
    "y_train, y_val = y[mask_train.values], y[mask_val.values]\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_titles = df_clean[mask_train]['title']\n",
    "val_titles = df_clean[mask_val]['title']\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=2)\n",
    "title_bow_train = title_vec.fit_transform(train_titles)\n",
    "title_bow_val = title_vec.transform(val_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Concat the BoW into features df\n",
    "X_train_title = hstack([X_train, title_bow_train])\n",
    "X_val_title = hstack([X_val, title_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "mdl = RandomForestClassifier(n_estimators=1000, random_state=42,\n",
    "                             class_weight=\"balanced\", n_jobs=8)\n",
    "mdl.fit(X_train_title, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proba = mdl.predict_proba(X_train_title)\n",
    "train_preds = mdl.predict(X_train_title)\n",
    "\n",
    "val_proba = mdl.predict_proba(X_val_title)\n",
    "val_preds = mdl.predict(X_val_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the metrics\n",
    "print('TRAIN METRICS:')\n",
    "print('log_loss: ', log_loss(y_train, train_preds))\n",
    "print('avg_precision_score: ', average_precision_score(y_train, train_proba[:, 1]))\n",
    "print('roc_auc: ', roc_auc_score(y_train, train_proba[:, 1]))\n",
    "\n",
    "print('\\nVALIDATION METRICS:')\n",
    "print('log_loss: ', log_loss(y_val, val_preds))\n",
    "print('avg_precision_score: ', average_precision_score(y_val, val_proba[:, 1]))\n",
    "print('roc_auc: ', roc_auc_score(y_val, val_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:youtube_recommender]",
   "language": "python",
   "name": "conda-env-youtube_recommender-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
