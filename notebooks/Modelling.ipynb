{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "from skopt import forest_minimize\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data_labeled.csv')\n",
    "\n",
    "df = df[df['y'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean date attribute\n",
    "clean_date = df['watch-time-text'].str.extract(r\"(\\d+) de ([a-z]+)\\. de (\\d+)\")\n",
    "clean_date[0] = clean_date[0].dropna().astype(str)\n",
    "clean_date[2] = clean_date[2].dropna().astype(str)\n",
    "\n",
    "month_map = {\"jan\": \"Jan\",\n",
    "             \"fev\": \"Feb\",\n",
    "             \"mar\": \"Mar\",\n",
    "             \"abr\": \"Apr\",\n",
    "             \"mai\": \"May\",\n",
    "             \"jun\": \"Jun\",\n",
    "             \"jul\": \"Jul\",\n",
    "             \"ago\": \"Aug\",\n",
    "             \"set\": \"Sep\",\n",
    "             \"out\": \"Oct\",\n",
    "             \"nov\": \"Nov\",\n",
    "             \"dez\": \"Dec\"}\n",
    "\n",
    "clean_date[1] = clean_date[1].map(month_map)\n",
    "clean_date = clean_date.dropna().apply(lambda x: \" \".join(x), axis=1)\n",
    "clean_date = pd.to_datetime(clean_date, format=\"%d %b %Y\")\n",
    "\n",
    "# Clean view number\n",
    "views = df['watch-view-count'].str.extract(r\"(\\d+\\.?\\d*)\", expand=False)\n",
    "views = views.str.replace(\".\", \"\").fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "y = df['y'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['time_since_pub'] = (pd.to_datetime(\"2020-03-24\") -  # HARDCODED\n",
    "                              clean_date) / np.timedelta64(1, 'D')\n",
    "\n",
    "# Extracting n of view feature\n",
    "features['views'] = views\n",
    "\n",
    "# Extracting n of view/day feature\n",
    "features['views_per_day'] = features['views'] / features['time_since_pub']\n",
    "\n",
    "# Droping time_since_pub to prevent bias\n",
    "features = features.drop(['time_since_pub'], axis=1)\n",
    "\n",
    "# Dropping problematic features\n",
    "y = y[features.index]\n",
    "df = df.loc[features.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = []\n",
    "for height, width in zip(df['og:video:height'], df['og:video:width']):\n",
    "    try:\n",
    "        height = float(height)\n",
    "        width = float(width)\n",
    "    except:\n",
    "        resolutions.append(np.nan)\n",
    "        continue\n",
    "        \n",
    "    resolutions.append(height*width)\n",
    "    \n",
    "features['resolution'] = resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Around 75% train and 25% to validation\n",
    "split_date = '2020-02-27'\n",
    "mask_train = (clean_date < split_date) & (clean_date.notnull())\n",
    "mask_val = (clean_date >= split_date) & (clean_date.notnull())\n",
    "\n",
    "X_train, X_val = features[mask_train.values], features[mask_val.values]\n",
    "y_train, y_val = y[mask_train.values], y[mask_val.values]\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NaNs\n",
    "X_train['resolution'] = X_train['resolution'].fillna(X_train['resolution'].mean())\n",
    "X_val['resolution'] = X_val['resolution'].fillna(X_train['resolution'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from title\n",
    "train_titles = df[mask_train]['watch-title']\n",
    "val_titles = df[mask_val]['watch-title']\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "title_bow_train = title_vec.fit_transform(train_titles)\n",
    "title_bow_val = title_vec.transform(val_titles)\n",
    "\n",
    "# Concat the BoW into features df\n",
    "X_train_title = hstack([X_train, title_bow_train])\n",
    "X_val_title = hstack([X_val, title_bow_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rfc = RandomForestClassifier(n_estimators=200, random_state=42,\n",
    "                             class_weight=\"balanced\", n_jobs=8)\n",
    "rfc.fit(X_train_title, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting\n",
    "rf_train_proba = rfc.predict_proba(X_train_title)\n",
    "rf_train_preds = rfc.predict(X_train_title)\n",
    "rf_val_proba = rfc.predict_proba(X_val_title)\n",
    "rf_val_preds = rfc.predict(X_val_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the metrics\n",
    "print('TRAIN METRICS:')\n",
    "print('log_loss: ', log_loss(y_train, rf_train_proba))\n",
    "print('avg_precision_score: ', average_precision_score(y_train, rf_train_proba[:, 1]))\n",
    "print('roc_auc: ', roc_auc_score(y_train, rf_train_proba[:, 1]))\n",
    "\n",
    "print('\\nVALIDATION METRICS:')\n",
    "print('log_loss: ', log_loss(y_val, rf_val_preds))\n",
    "print('avg_precision_score: ', average_precision_score(y_val, rf_val_proba[:, 1]))\n",
    "print('roc_auc: ', roc_auc_score(y_val, rf_val_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(random_state=42, class_weight=\"balanced\", n_jobs=7)\n",
    "lgbm.fit(X_train_title, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting\n",
    "lgbm_train_proba = lgbm.predict_proba(X_train_title)\n",
    "lgbm_train_preds = lgbm.predict(X_train_title)\n",
    "lgbm_val_proba = lgbm.predict_proba(X_val_title)\n",
    "lgbm_val_preds = lgbm.predict(X_val_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the metrics\n",
    "print('TRAIN METRICS:')\n",
    "print('log_loss: ', log_loss(y_train, lgbm_train_preds))\n",
    "print('avg_precision_score: ', average_precision_score(y_train, lgbm_train_proba[:, 1]))\n",
    "print('roc_auc: ', roc_auc_score(y_train, lgbm_train_proba[:, 1]))\n",
    "\n",
    "print('\\nVALIDATION METRICS:')\n",
    "print('log_loss: ', log_loss(y_val, lgbm_val_preds))\n",
    "print('avg_precision_score: ', average_precision_score(y_val, lgbm_val_proba[:, 1]))\n",
    "print('roc_auc: ', roc_auc_score(y_val, lgbm_val_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgbm(params):\n",
    "    print(params)\n",
    "    lr = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    n_estimators = params[5]\n",
    "    \n",
    "    min_df = params[6]\n",
    "    ngram_range = (1, params[7])\n",
    "    \n",
    "    title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "    title_bow_train = title_vec.fit_transform(train_titles)\n",
    "    title_bow_val = title_vec.transform(val_titles)\n",
    "    \n",
    "    X_train_title = hstack([X_train, title_bow_train])\n",
    "    X_val_title = hstack([X_val, title_bow_val])\n",
    "\n",
    "    mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                         min_child_samples=min_child_samples, subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                         class_weight=\"balanced\", n_jobs=8)\n",
    "    mdl.fit(X_train_title, y_train)\n",
    "    \n",
    "    p = mdl.predict_proba(X_val_title)[:, 1]\n",
    "    \n",
    "    print(roc_auc_score(y_val, p))\n",
    "    \n",
    "    return -average_precision_score(y_val, p)\n",
    "\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), # lr\n",
    "          (1, 10), # max_depth\n",
    "          (1, 20), # min_child_samples\n",
    "          (0.05, 1.), # subsample\n",
    "          (0.05, 1.), # colsample_bytree\n",
    "          (100,1000), # n_estimators\n",
    "          (1,5), # min_df\n",
    "          (1,5)] # ngram_range\n",
    "\n",
    "res = forest_minimize(tune_lgbm, space, random_state=160745, n_random_starts=20, n_calls=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, max_depth, min_child_samples, subsample, colsample_bytree, n_estimators, min_df, ngram_range = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1, ngram_range)\n",
    "title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "title_bow_train = title_vec.fit_transform(train_titles)\n",
    "title_bow_val = title_vec.transform(val_titles)\n",
    "\n",
    "X_train_title = hstack([X_train, title_bow_train])\n",
    "X_val_title = hstack([X_val, title_bow_val])\n",
    "\n",
    "lgbm = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                     min_child_samples=min_child_samples, subsample=subsample,\n",
    "                     colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                     class_weight='balanced', n_jobs=8)\n",
    "lgbm.fit(X_train_title, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train_proba = lgbm.predict_proba(X_train_title)\n",
    "lgbm_train_preds = lgbm.predict(X_train_title)\n",
    "lgbm_val_proba = lgbm.predict_proba(X_val_title)\n",
    "lgbm_val_preds = lgbm.predict(X_val_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the metrics\n",
    "print('TRAIN METRICS:')\n",
    "print('log_loss: ', log_loss(y_train, lgbm_train_preds))\n",
    "print('avg_precision_score: ', average_precision_score(y_train, lgbm_train_proba[:, 1]))\n",
    "print('roc_auc: ', roc_auc_score(y_train, lgbm_train_proba[:, 1]))\n",
    "\n",
    "print('\\nVALIDATION METRICS:')\n",
    "print('log_loss: ', log_loss(y_val, lgbm_val_preds))\n",
    "print('avg_precision_score: ', average_precision_score(y_val, lgbm_val_proba[:, 1]))\n",
    "print('roc_auc: ', roc_auc_score(y_val, lgbm_val_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"RF\": rf_val_proba[:, 1], \"LGBM\": lgbm_val_proba[:, 1]}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_weights = np.linspace(0,1,20)\n",
    "\n",
    "for rf_weight in rf_weights:\n",
    "    p = rf_weight*rf_val_proba[:, 1] + (1-rf_weight)*lgbm_val_proba[:, 1]\n",
    "    print(rf_weight)\n",
    "    print(average_precision_score(y_val, p), roc_auc_score(y_val, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.26*rf_val_proba[:, 1] + 0.74*lgbm_val_proba[:, 1]\n",
    "print(average_precision_score(y_val, p), roc_auc_score(y_val, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jb\n",
    "jb.dump(lgbm, \"../pkls/lgbm_20200324.pkl.z\")\n",
    "jb.dump(rfc, \"../pkls/rf_20200324.pkl.z\")\n",
    "jb.dump(title_vec, \"../pkls/titlebow_20200324.pkl.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:youtube_recommender]",
   "language": "python",
   "name": "conda-env-youtube_recommender-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
